{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1일차 앙상블 85.4\n",
    "#2일차,3일차 신경망 테스트 84\n",
    "\n",
    "#신경망의 경우 모델의 복잡도를 낮추거나 올려도 테스트 데이터의 정확도가 84를 넘지 않음\n",
    "#데이터 전처리가 필요하다고 판단\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요 라이브러리들 import\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 데이터 크기: (17480, 16)\n",
      "테스트용 데이터 크기: (15081, 15)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기 및 크기 확인\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"훈련용 데이터 크기:\", train_data.shape)\n",
    "print(\"테스트용 데이터 크기:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치가 있는 컬럼은: workclass 입니다\n",
      "해당 컬럼에 총 1836 개의 결측치가 존재합니다.\n",
      "결측치가 있는 컬럼은: occupation 입니다\n",
      "해당 컬럼에 총 1843 개의 결측치가 존재합니다.\n",
      "결측치가 있는 컬럼은: native.country 입니다\n",
      "해당 컬럼에 총 583 개의 결측치가 존재합니다.\n",
      "[['workclass', dtype('O')], ['occupation', dtype('O')], ['native.country', dtype('O')]]\n"
     ]
    }
   ],
   "source": [
    "#결측치 제거 함수\n",
    "\n",
    "def check_missing_col(dataframe):\n",
    "    missing_col = []\n",
    "    for col in dataframe.columns:\n",
    "        missing_values = sum(dataframe[col].isna())\n",
    "        is_missing = True if missing_values >= 1 else False\n",
    "        if is_missing:\n",
    "            print(f'결측치가 있는 컬럼은: {col} 입니다')\n",
    "            print(f'해당 컬럼에 총 {missing_values} 개의 결측치가 존재합니다.')\n",
    "            missing_col.append([col, dataframe[col].dtype])\n",
    "    if missing_col == []:\n",
    "        print('결측치가 존재하지 않습니다')\n",
    "    return missing_col\n",
    "\n",
    "\n",
    "missing_col = check_missing_col(train_data)\n",
    "print(missing_col)\n",
    "\n",
    "train_data.dropna(axis=0,subset=['workclass','occupation','native.country'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 데이터: (15081, 14)\n",
      "테스트용 라벨: (15081,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data.drop(['id', 'target'], axis=1)\n",
    "y_train = train_data['target']\n",
    "\n",
    "test_data=test_data.drop(['id'], axis=1)\n",
    "\n",
    "\n",
    "print(\"훈련용 데이터:\", x_train.shape)\n",
    "print(\"테스트용 라벨:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨인코딩을 하기 위함 dictionary map 생성 함수\n",
    "def make_label_map(dataframe):\n",
    "    label_maps = {}\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype=='object':\n",
    "            label_map = {'unknown':0}\n",
    "            for i, key in enumerate(dataframe[col].unique()):\n",
    "                label_map[key] = i  #새로 등장하는 유니크 값들에 대해 1부터 1씩 증가시켜 키값을 부여해줍니다.\n",
    "            label_maps[col] = label_map\n",
    "    return label_maps\n",
    "\n",
    "# 각 범주형 변수에 인코딩 값을 부여하는 함수\n",
    "def label_encoder(dataframe, label_map):\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype=='object':\n",
    "            dataframe[col] = dataframe[col].map(label_map[col])\n",
    "            #dataframe[col] = dataframe[col].fillna(label_map[col]['unknown']) #혹시 모를 결측값은 unknown의 값(0)으로 채워줍니다.\n",
    "    return dataframe\n",
    "\n",
    "x_train = label_encoder(x_train, make_label_map(x_train))\n",
    "\n",
    "#제출용 라벨링 데이터 변환\n",
    "test_data = label_encoder(test_data, make_label_map(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train,Y_test = train_test_split(x_train, y_train, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOME\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train_over,y_train_over = smote.fit_resample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vals = np.mean(X_train_over, axis=0)\n",
    "std_val = np.std(X_train_over)\n",
    "\n",
    "X_train_centered = (X_train_over  - mean_vals) / std_val\n",
    "\n",
    "mean_vals = np.mean(X_test, axis=0)\n",
    "std_val = np.std(X_test)\n",
    "\n",
    "X_test_centered = (X_test- mean_vals) / std_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#원핫 인코딩 생성\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train_over)\n",
    "print(y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=X_train_centered.shape[1],\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=30,\n",
    "    input_dim=50,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "    )\n",
    ")\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=100,\n",
    "    input_dim=150,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=50,\n",
    "    input_dim=100,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=30,\n",
    "    input_dim=50,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=20,\n",
    "    input_dim=30,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='tanh'\n",
    "    )\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "    units=y_train_onehot.shape[1],\n",
    "    input_dim=30,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='softmax'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                750       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 2,342\n",
      "Trainable params: 2,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'], loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8591\n",
      "Epoch 2/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8596\n",
      "Epoch 3/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3176 - accuracy: 0.8596\n",
      "Epoch 4/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3162 - accuracy: 0.8600\n",
      "Epoch 5/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3131 - accuracy: 0.8622\n",
      "Epoch 6/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3098 - accuracy: 0.8626\n",
      "Epoch 8/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3075 - accuracy: 0.8634\n",
      "Epoch 9/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8652\n",
      "Epoch 10/10\n",
      "530/530 [==============================] - 1s 2ms/step - loss: 0.3058 - accuracy: 0.8649\n"
     ]
    }
   ],
   "source": [
    "#early_stopping = EarlyStopping()\n",
    "history = model.fit(X_train_centered, y_train_onehot, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yong\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 최종 결과 0.869139010275186\n",
      "test 최종 결과 0.7401219835587377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yong\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_train_pred= model.predict_classes(X_train_centered, verbose=0)\n",
    "correct_preds = np.sum(y_train_over == y_train_pred, axis=0)\n",
    "\n",
    "train_acc = correct_preds / y_train_over.shape[0]\n",
    "\n",
    "y_test_pred= model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds = np.sum(Y_test == y_test_pred, axis=0)\n",
    "\n",
    "test_acc = correct_preds / Y_test.shape[0]\n",
    "\n",
    "print(\"train 최종 결과\", train_acc)\n",
    "print(\"test 최종 결과\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
